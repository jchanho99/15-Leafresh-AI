# chatbot_llm_model_vertex.py
import vertexai
from vertexai.generative_models import GenerativeModel
from google.oauth2 import service_account
from dotenv import load_dotenv
import os
import json
import re

load_dotenv()

#  í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸°
SERVICE_ACCOUNT_FILE = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
PROJECT_ID = os.getenv("GOOGLE_CLOUD_PROJECT", "kakao-project-457106")
LOCATION = os.getenv("VERTEX_AI_LOCATION", "us-central1")
MODEL_NAME = os.getenv("VERTEX_MODEL_NAME", "publishers/google/models/gemini-1.5-flash")

# Vertex AI ì´ˆê¸°í™”
credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE)
vertexai.init(project=PROJECT_ID, location=LOCATION, credentials=credentials)

#  ëª¨ë¸ ê°ì²´ ìƒì„±
model = GenerativeModel("gemini-1.5-flash")

#  LLM ì‘ë‹µ í•¨ìˆ˜
def get_llm_response(prompt: str):
    try:
        response = model.generate_content(prompt)

        # ì•ˆì „í•˜ê²Œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        raw_text = getattr(response, "text", "")
        print("ğŸ“¦ Gemini ì‘ë‹µ ì „ì²´:", raw_text)

        # JSON í˜•ì‹ ì¶”ì¶œ
        match = re.search(r'{.*}', raw_text, re.DOTALL)
        if match:
            return json.loads(match.group())

        return {"status": 500, "message": "âŒ JSON ë¸”ë¡ íŒŒì‹± ì‹¤íŒ¨", "data": None}

    except Exception as e:
        return {"status": 500, "message": f"âŒ Gemini í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}", "data": None}